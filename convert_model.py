import tensorflow as tf
from tensorflow import keras
import numpy as np
import json
import os

# --- é…ç½® ---
H5_MODEL_PATH = 'fashion_mnist_model.h5' # æ‚¨çš„ .h5 æ¨¡å‹æª”æ¡ˆåç¨±
OUTPUT_MODEL_DIR = 'model'
OUTPUT_JSON_PATH = os.path.join(OUTPUT_MODEL_DIR, 'fashion_mnist.json')
OUTPUT_WEIGHTS_PATH = os.path.join(OUTPUT_MODEL_DIR, 'fashion_mnist.npz')

def convert_h5_to_json_npz(h5_path, output_json_path, output_weights_path):
    """
    å°‡ Keras .h5 æ¨¡å‹è½‰æ›ç‚º nn_predict.py æ‰€éœ€çš„ .json (æ¶æ§‹) å’Œ .npz (æ¬Šé‡) æ ¼å¼ã€‚
    æ­¤ç‰ˆæœ¬æ ¹æ“šç”¨æˆ¶æä¾›çš„ numpy_nn_test.ipynb ä¸­çš„é‚è¼¯é€²è¡Œä¿®æ”¹ã€‚
    """
    print(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹: {h5_path}")
    try:
        model = keras.models.load_model(h5_path)
        print("æ¨¡å‹è¼‰å…¥æˆåŠŸã€‚")
        model.summary()
    except Exception as e:
        print(f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        return

    # --- 1. æå–ä¸¦å„²å­˜æ¨¡å‹æ¬Šé‡ (fashion_mnist.npz) ---
    # åƒè€ƒ numpy_nn_test.ipynb ä¸­çš„ Step 2 & 3
    model_weights_dict = {}
    print("\nğŸ” æ­£åœ¨å¾æ¨¡å‹ä¸­æå–æ¬Šé‡...")
    for layer in model.layers:
        layer_weights = layer.get_weights()
        if layer_weights: # åªè™•ç†æœ‰æ¬Šé‡çš„å±¤
            # print(f"å±¤: {layer.name}") # å¯é¸çš„è©³ç´°è¼¸å‡º
            for i, w_array in enumerate(layer_weights):
                param_name = f"{layer.name}_{i}" # ä¾‹å¦‚ dense_1_0, dense_1_1
                # print(f"  {param_name}: shape={w_array.shape}") # å¯é¸çš„è©³ç´°è¼¸å‡º
                model_weights_dict[param_name] = w_array
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    if not os.path.exists(OUTPUT_MODEL_DIR):
        os.makedirs(OUTPUT_MODEL_DIR)
        print(f"å·²å»ºç«‹ç›®éŒ„: {OUTPUT_MODEL_DIR}")

    print(f"\næ­£åœ¨å„²å­˜æ¨¡å‹æ¬Šé‡åˆ°: {output_weights_path}")
    try:
        np.savez(output_weights_path, **model_weights_dict)
        print("âœ… æ¨¡å‹æ¬Šé‡å„²å­˜æˆåŠŸã€‚")
    except Exception as e:
        print(f"å„²å­˜æ¨¡å‹æ¬Šé‡å¤±æ•—: {e}")
        return

    # --- 2. æå–ä¸¦å„²å­˜æ¨¡å‹æ¶æ§‹ (fashion_mnist.json) ---
    # åƒè€ƒ numpy_nn_test.ipynb ä¸­çš„ Step 6
    model_arch_list = []
    print("\nğŸ“œ æ­£åœ¨æå–æ¨¡å‹æ¶æ§‹...")
    for layer in model.layers:
        if layer.__class__.__name__ == 'InputLayer': # è·³é InputLayer
            continue

        layer_config = layer.get_config()
        layer_info = {
            "name": layer.name,
            "type": layer.__class__.__name__, # ä¾‹å¦‚ "Dense", "Flatten"
            "config": layer_config, # å„²å­˜å®Œæ•´çš„ Keras å±¤é…ç½®
            "weights": [f"{layer.name}_{i}" for i in range(len(layer.get_weights()))]
        }
        model_arch_list.append(layer_info)

    print(f"\næ­£åœ¨å„²å­˜æ¨¡å‹æ¶æ§‹åˆ°: {output_json_path}")
    try:
        with open(output_json_path, 'w') as f:
            json.dump(model_arch_list, f, indent=2) # ä½¿ç”¨ indent=2 èˆ‡ç­†è¨˜æœ¬ä¸€è‡´
        print("âœ… æ¨¡å‹æ¶æ§‹å„²å­˜æˆåŠŸã€‚")
    except Exception as e:
        print(f"å„²å­˜æ¨¡å‹æ¶æ§‹å¤±æ•—: {e}")
        return

    print("\næ¨¡å‹è½‰æ›å®Œæˆï¼")
    print(f"æ¶æ§‹æª”æ¡ˆ: {output_json_path}")
    print(f"æ¬Šé‡æª”æ¡ˆ: {output_weights_path}")

if __name__ == '__main__':
    if not os.path.exists(H5_MODEL_PATH):
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ° H5 æ¨¡å‹æª”æ¡ˆ '{H5_MODEL_PATH}'ã€‚")
        print(f"è«‹ç¢ºèªåç‚º '{H5_MODEL_PATH}' çš„æª”æ¡ˆå­˜åœ¨æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼Œæˆ–è€…ä¿®æ”¹ H5_MODEL_PATH è®Šæ•¸ã€‚")
    else:
        # ç¢ºä¿ TensorFlow ä¸è¦ä½”ç”¨æ‰€æœ‰ GPU è¨˜æ†¶é«” (å¦‚æœæœ‰çš„è©±)ï¼Œé›–ç„¶å°æ–¼è½‰æ›å¯èƒ½ä¸æ˜¯å¤§å•é¡Œ
        try:
            gpus = tf.config.experimental.list_physical_devices('GPU')
            if gpus:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                print("å·²ç‚º GPU è¨­å®šè¨˜æ†¶é«”å¢é•·æ¨¡å¼ã€‚")
        except RuntimeError as e:
            print(f"è¨­å®š GPU è¨˜æ†¶é«”æ™‚ç™¼ç”ŸéŒ¯èª¤ (å¯å¿½ç•¥): {e}")
            
        convert_h5_to_json_npz(H5_MODEL_PATH, OUTPUT_JSON_PATH, OUTPUT_WEIGHTS_PATH)